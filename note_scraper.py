
import requests
from bs4 import BeautifulSoup
import time
import random
import datetime
import os
import re
import warnings
import html
from bs4 import XMLParsedAsHTMLWarning
warnings.filterwarnings("ignore", category=XMLParsedAsHTMLWarning)

# ==========================================
# 1. è¨­å®šã‚¨ãƒªã‚¢
# ==========================================

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
}

OUTPUT_FILENAME = "index.html"
MAX_ARTICLES_PER_FEED = 10

# RSSãƒ•ã‚£ãƒ¼ãƒ‰è¨­å®šï¼ˆHTMLæ§‹é€ ã«ä¾å­˜ã—ãªã„XMLæ–¹å¼ï¼‰
FEED_CONFIGS = {
    "æœã®æ–°è": {
        "site_name": "ãƒ­ã‚¤ã‚¿ãƒ¼é€šä¿¡ (ãƒ†ãƒƒã‚¯)",
        "rss_url": "https://news.google.com/rss/search?q=site:jp.reuters.com%20technology&hl=ja&gl=JP&ceid=JP:ja",
    },
    "å‰µä½œã®ãƒã‚¿": {
        "site_name": "WIRED (ã‚µã‚¤ã‚¨ãƒ³ã‚¹)",
        "rss_url": "https://news.google.com/rss/search?q=site:wired.jp%20science&hl=ja&gl=JP&ceid=JP:ja",
    },
    "å¥½å¥‡å¿ƒ": {
        "site_name": "ãƒŠã‚·ãƒ§ãƒŠãƒ« ã‚¸ã‚ªã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯",
        "rss_url": "https://news.google.com/rss/search?q=site:natgeo.nikkeibp.co.jp&hl=ja&gl=JP&ceid=JP:ja",
    }
}

# ==========================================
# 2. RSSå–å¾—ç”¨ã‚¯ãƒ©ã‚¹
# ==========================================

class RSSScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(HEADERS)

    def get_soup(self, url):
        """URLã‹ã‚‰BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾— (å¯èƒ½ãªé™ã‚ŠXMLã¨ã—ã¦è§£æ)"""
        try:
            response = self.session.get(url, timeout=25)
            response.raise_for_status()
            
            # features="xml" ã‚’è©¦ã¿ã‚‹ (lxmlãŒå¿…è¦)
            # ã‚‚ã—lxmlãŒãªã„å ´åˆã¯è‡ªå‹•çš„ã« html.parser ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã•ã‚Œã‚‹ãŒæ˜ç¤ºçš„ã«æ›¸ã
            try:
                soup = BeautifulSoup(response.content, features="xml")
            except Exception:
                # å¤±æ•—ã—ãŸå ´åˆã¯æ¨™æº–ã® html.parser ã‚’ä½¿ç”¨ (ã‚¿ã‚°åãŒå°æ–‡å­—ã«ãªã‚‹ç‚¹ã«æ³¨æ„)
                soup = BeautifulSoup(response.content, features="html.parser")
            return soup
        except Exception as e:
            print(f"   âš ï¸ ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—å¤±æ•— ({url}): {e}")
            return None

    def scrape_category(self, category, config):
        """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹æƒ…å ±ã‚’æŠ½å‡º"""
        print(f"ğŸ” RSSå–å¾—ä¸­: {config['site_name']} ({category})")
        soup = self.get_soup(config['rss_url'])
        if not soup: return []

        articles = []
        # RSS 1.0/2.0 ä¸¡æ–¹ã® item ã‚¿ã‚°ã«å¯¾å¿œ
        items = soup.find_all('item')
        
        count = 0
        for item in items:
            if count >= MAX_ARTICLES_PER_FEED: break
            try:
                # ã‚¿ã‚¤ãƒˆãƒ«ã®å–å¾—
                title_tag = item.find('title')
                if not title_tag: continue
                title = title_tag.text.strip()
                
                # ãƒªãƒ³ã‚¯ã®å–å¾—
                link_tag = item.find('link')
                if not link_tag: continue
                link = link_tag.text.strip()
                
                # linkã‚¿ã‚°ãŒç©ºã§ã‚‚ item ã® next_sibling ç­‰ã«ã‚ã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚è£œå®Œï¼ˆBS4ã®XMLãƒ‘ãƒ¼ã‚¹æŒ™å‹•å¯¾ç­–ï¼‰
                if not link:
                    link = item.link.next_sibling.strip() if item.link and item.link.next_sibling else ""
                
                if not link: continue
                
                # å…¬é–‹æ—¥æ™‚ã®å–å¾— (pubDate, dc:date, date ãªã©ã«å¯¾å¿œ)
                # html.parser ã®å ´åˆã¯ã‚¿ã‚°åãŒå°æ–‡å­—ã«ãªã‚‹ãŸã‚ä¸¡æ–¹ãƒã‚§ãƒƒã‚¯
                date_tag = (item.find('pubDate') or item.find('pubdate') or 
                            item.find('dc:date') or item.find('date'))
                pub_date = date_tag.text.strip() if date_tag else ""
                
                # æ—¥ä»˜è¡¨ç¤ºã®æ•´å½¢ (RSSã®å¤šæ§˜ãªå½¢å¼ã«å¯¾å¿œ)
                display_date = pub_date
                if pub_date:
                    # ç°¡æ˜“çš„ãªæŠ½å‡º: RFC822å½¢å¼(ãƒ­ã‚¤ã‚¿ãƒ¼)ã‚„ISOå½¢å¼(ãƒŠã‚·ãƒ§ã‚¸ã‚ª)ã‹ã‚‰æœˆ/æ—¥ã‚’æ¨æ¸¬
                    match = re.search(r'(\d{1,2})\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)', pub_date, re.I)
                    if match:
                        display_date = f"{match.group(2)} {match.group(1)}"
                    else:
                        match = re.search(r'(\d{4})-(\d{1,2})-(\d{1,2})', pub_date)
                        if match:
                            display_date = f"{match.group(2)}/{match.group(3)}"
                
                # æ¦‚è¦ã®å–å¾—
                desc_tag = item.find('description')
                description = desc_tag.text.strip() if desc_tag else ""
                # HTMLã‚¿ã‚°ã®é™¤å»ã¨æ–‡å­—æ•°åˆ¶é™
                if description:
                    description = re.sub(r'<[^>]+>', '', description)
                    description = description.replace('\n', ' ').strip()
                    if len(description) > 100:
                        description = description[:100] + "..."

                # é‡è¤‡å›é¿
                if any(art['url'] == link for art in articles): continue

                # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†ï¼ˆç‰¹æ®Šæ–‡å­—ã«ã‚ˆã‚‹HTMLå´©ã‚Œã‚„è­¦å‘Šã‚’é˜²æ­¢ï¼‰
                safe_title = html.escape(html.unescape(title))
                safe_link = html.escape(link)
                safe_description = html.escape(html.unescape(description))

                articles.append({
                    "title": safe_title,
                    "url": safe_link,
                    "site": config['site_name'],
                    "date": display_date,
                    "description": safe_description
                })
                count += 1
            except Exception:
                continue
        
        print(f"   âœ¨ {len(articles)}ä»¶ã®è¨˜äº‹ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        return articles

# ==========================================
# 3. HTMLç”Ÿæˆã‚¯ãƒ©ã‚¹ (ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ + æ¦‚è¦è¡¨ç¤º)
# ==========================================

class HtmlGenerator:
    def __init__(self, data):
        self.data = data

    def generate(self):
        """åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        today = datetime.date.today().strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RSS News Patrol</title>
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@400;700&family=Noto+Sans+JP:wght@400;700&display=swap" rel="stylesheet">
    <style>
        :root {{
            --bg: #f8fafc;
            --primary: #2563eb;
            --primary-dark: #1d4ed8;
            --text-main: #0f172a;
            --text-muted: #64748b;
            --card-bg: #ffffff;
            --border: #e2e8f0;
        }}
        @media (prefers-color-scheme: dark) {{
            :root {{
                --bg: #0f172a;
                --card-bg: #1e293b;
                --text-main: #f1f5f9;
                --text-muted: #94a3b8;
                --border: #334155;
            }}
        }}
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: 'Outfit', 'Noto Sans JP', sans-serif;
            background: var(--bg);
            color: var(--text-main);
            line-height: 1.6;
            padding: 20px;
        }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        header {{
            text-align: center;
            margin-bottom: 40px;
            padding: 50px 20px;
            background: linear-gradient(135deg, #1e3a8a, #3b82f6);
            color: white;
            border-radius: 32px;
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
        }}
        header h1 {{ font-size: 3rem; margin-bottom: 10px; font-weight: 700; letter-spacing: -0.05em; }}
        header p {{ font-size: 1.1rem; opacity: 0.9; }}

        .tabs {{
            display: flex;
            justify-content: center;
            gap: 12px;
            margin-bottom: 30px;
            overflow-x: auto;
            padding: 10px;
            scrollbar-width: none;
        }}
        .tabs::-webkit-scrollbar {{ display: none; }}
        
        .tab-btn {{
            padding: 12px 28px;
            border: 1px solid var(--border);
            background: var(--card-bg);
            color: var(--text-main);
            border-radius: 99px;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.3s;
            white-space: nowrap;
        }}
        .tab-btn.active {{
            background: var(--primary);
            color: white;
            border-color: var(--primary);
            box-shadow: 0 4px 12px rgba(37, 99, 235, 0.3);
        }}

        .tab-content {{ display: none; animation: fadeIn 0.5s ease; }}
        .tab-content.active {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(350px, 1fr)); gap: 25px; }}

        .card {{
            background: var(--card-bg);
            border-radius: 20px;
            padding: 25px;
            display: flex;
            flex-direction: column;
            transition: transform 0.3s, box-shadow 0.3s;
            text-decoration: none;
            color: inherit;
            border: 1px solid var(--border);
        }}
        .card:hover {{
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0,0,0,0.1);
            border-color: var(--primary);
        }}
        .card h3 {{
            font-size: 1.2rem;
            font-weight: 700;
            margin-bottom: 12px;
            line-height: 1.4;
            display: -webkit-box;
            -webkit-line-clamp: 3;
            -webkit-box-orient: vertical;
            overflow: hidden;
        }}
        .description {{
            font-size: 0.9rem;
            color: var(--text-muted);
            margin-bottom: 15px;
            display: -webkit-box;
            -webkit-line-clamp: 3;
            -webkit-box-orient: vertical;
            overflow: hidden;
            flex-grow: 1;
        }}
        .card-footer {{
            margin-top: auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.8rem;
            color: var(--text-muted);
            padding-top: 15px;
            border-top: 1px solid var(--border);
        }}
        .badge {{
            background: #eff6ff;
            color: #2563eb;
            padding: 4px 10px;
            border-radius: 6px;
            font-weight: 700;
            font-size: 0.75rem;
        }}
        @media (prefers-color-scheme: dark) {{
            .badge {{ background: #1e293b; color: #60a5fa; }}
        }}

        @keyframes fadeIn {{ from {{ opacity: 0; transform: translateY(10px); }} to {{ opacity: 1; transform: translateY(0); }} }}
        footer {{ text-align: center; margin-top: 80px; padding: 40px; color: var(--text-muted); border-top: 1px solid var(--border); }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>News Patrol</h1>
            <p>{today} | å³é¸ã•ã‚ŒãŸæœ€æ–°ãƒˆãƒ”ãƒƒã‚¯ (RSSãƒ•ã‚£ãƒ¼ãƒ‰)</p>
        </header>

        <div class="tabs">
            <button class="tab-btn active" onclick="openTab(event, 'morning')">æœã®æ–°è</button>
            <button class="tab-btn" onclick="openTab(event, 'creative')">å‰µä½œã®ãƒã‚¿</button>
            <button class="tab-btn" onclick="openTab(event, 'curiosity')">å¥½å¥‡å¿ƒ</button>
        </div>

        {self._gen_section('morning', self.data.get('æœã®æ–°è', []), True)}
        {self._gen_section('creative', self.data.get('å‰µä½œã®ãƒã‚¿', []))}
        {self._gen_section('curiosity', self.data.get('å¥½å¥‡å¿ƒ', []))}

        <footer>
            <p>&copy; 2026 RSS Scraper Pro. Modern News Delivery.</p>
        </footer>
    </div>

    <script>
        function openTab(e, id) {{
            document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
            document.querySelectorAll('.tab-btn').forEach(b => b.classList.remove('active'));
            const target = document.getElementById(id);
            if (target) target.classList.add('active');
            if (e && e.currentTarget) e.currentTarget.classList.add('active');
        }}
    </script>
</body>
</html>
"""
        return html

    def _gen_section(self, section_id, articles, active=False):
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã®HTMLè¦ç´ ã‚’ç”Ÿæˆ"""
        status_class = "tab-content active" if active else "tab-content"
        html = f'<div id="{section_id}" class="{status_class}">'
        
        if not articles:
            html += '<div style="grid-column: 1/-1; text-align: center; padding: 60px; color: var(--text-muted);">æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚</div>'
        else:
            for a in articles:
                desc_html = f'<p class="description">{a["description"]}</p>' if a.get('description') else ""
                html += f"""
                <a href="{a['url']}" target="_blank" rel="noopener" class="card">
                    <h3>{a['title']}</h3>
                    {desc_html}
                    <div class="card-footer">
                        <span class="badge">{a['site']}</span>
                        <span>{a['date']}</span>
                    </div>
                </a>"""
        
        html += '</div>'
        return html

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================

def main():
    print("ğŸš€ RSSãƒ•ã‚£ãƒ¼ãƒ‰å·¡å›ã‚’é–‹å§‹ã—ã¾ã™...")
    scraper = RSSScraper()
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ– (æ§‹æ–‡ã‚¨ãƒ©ãƒ¼é˜²æ­¢ã®ãŸã‚ã‚·ãƒ³ãƒ—ãƒ«ã«)
    collected_data = {}
    collected_data["æœã®æ–°è"] = []
    collected_data["å‰µä½œã®ãƒã‚¿"] = []
    collected_data["å¥½å¥‡å¿ƒ"] = []

    # å„ã‚«ãƒ†ã‚´ãƒªã®ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    for category, config in FEED_CONFIGS.items():
        try:
            # ãƒ•ã‚£ãƒ¼ãƒ‰ã”ã¨ã«ç‹¬ç«‹ã—ã¦å‡¦ç†ã—ã€ä¸€ã‚«æ‰€ã®ã‚¨ãƒ©ãƒ¼ãŒå…¨ä½“ã«å½±éŸ¿ã—ãªã„ã‚ˆã†ã«ã™ã‚‹
            articles = scraper.scrape_category(category, config)
            collected_data[category] = articles
        except Exception as e:
            print(f"   ğŸ”¥ ã‚«ãƒ†ã‚´ãƒªã€Œ{category}ã€ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€ç¶šè¡Œã—ã¾ã™: {e}")

    # HTMLç”Ÿæˆã¨ä¿å­˜
    print("\nğŸ“ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆä¸­...")
    generator = HtmlGenerator(collected_data)
    html_content = generator.generate()
    
    try:
        with open(OUTPUT_FILENAME, "w", encoding="utf-8") as f:
            f.write(html_content)
        print(f"\nâœ… å®Œäº†ï¼çµæœã‚’ {OUTPUT_FILENAME} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"   âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()